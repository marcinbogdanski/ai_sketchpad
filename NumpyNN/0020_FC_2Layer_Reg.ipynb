{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "$$ \\huge{\\underline{\\textbf{ 2-Layer Neural Network - Regression }}} $$\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "    \n",
    "Contents:\n",
    "* [Introduction](#Introduction)\n",
    "* [Load and Explore Data](#Load-and-Explore-Data)\n",
    "* [Preprocess](#Preprocess)\n",
    "* [Neural Network](#Neural-Network)\n",
    "* [Train Estimator](#Train-Estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents simple **2-layer neural network** used for regression.\n",
    "\n",
    "**Model**\n",
    "\n",
    "* 1st layer: **fully connected** with **sigmoid** activation \n",
    "* 2nd (output) layer: **fully connected** with **linear** activation (i.e. no actiavtion)\n",
    "* loss: **mean squared error**\n",
    "* optimizer: **vanilla SGD**\n",
    "\n",
    "**Recommended Reading**\n",
    "\n",
    "* *Neural Networks and Deep Learning* by Michael Nilsen - great free introductory book [here](http://neuralnetworksanddeeplearning.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function contains everything. Pass in full dataset (inputs x, targets y) and randomly initialized weights $W$ and biases $b$. This function trains on mini-batches. $W$ and $b$ are updated in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(x_train, x_train, nb_epochs, batch_size, Wh, bh, Wo, bo):\n",
    "    \"\"\"Params:\n",
    "        x_train - inputs  - shape: (train_dataset_size, nb_inputs)\n",
    "        x_train - targets - shape: (train_dataset_size, nb_outputs)\n",
    "        nb_epochs - nb of full passes over train dataset x\n",
    "        batch_size - mini-batch size\n",
    "        Wh - hidden layer weights, modified in place - shape: (nb_inputs, nb_hidden)\n",
    "        bh - hidden layer biases, modified in place  - shape: (1, nb_hidden)\n",
    "        Wo - output layer weights, modified in place - shape: (nb_hidden, nb_output)\n",
    "        bh - output layer biases, modified in place  - shape: (1, nb_output)\n",
    "    \"\"\"\n",
    "    losses = []                                                 # keep track of losses for plotting\n",
    "\n",
    "    indices = np.array(range(len(x_train)))\n",
    "    for e in range(nb_epochs):\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        for batch_idx in range(0, len(x_train), batch_size):\n",
    "            \n",
    "            # Pick mext mini-batch\n",
    "            x = x_train[batch_idx : batch_idx+batch_size]\n",
    "            y = y_train[batch_idx : batch_idx+batch_size]\n",
    "            \n",
    "            # Forward Pass\n",
    "            z_hid = x @ Wh + bh                                 # (eq 1)    z.shape: (batch_size, nb_neurons)\n",
    "            h_hid = sigmoid(z_hid)                              # (eq 2)    y_hat.shape: (batch_size, nb_neurons)\n",
    "            \n",
    "            y_hat = h_hid @ Wo                                  #           no activation function,\n",
    "                                                                #           y_hat.shape: (batch_size, nb_outputs)\n",
    "                \n",
    "            # Backward Pass\n",
    "            ro_out = -(y-y_hat)                                 # no transfer function\n",
    "            dWh_out = h_hid.T @ ro_out\n",
    "\n",
    "            ro_hid = (ro_out @ W_out.T) * sigmoid_deriv(z_hid)\n",
    "            dW_hid = x.T @ ro_hid\n",
    "        \n",
    "        # Backward Pass\n",
    "        rho = y_hat - y                                         # (eq 3)    combined sigmoid and binary CE derivative\n",
    "        dW = (x.T @ rho) / len(x)                               # (eq 6)    backprop through matmul\n",
    "        db = np.sum(rho, axis=0, keepdims=True) / len(x)        # (eq 7)\n",
    "        \n",
    "        # Gradient Check (defined at the end of the notebook)\n",
    "        # ngW, ngb = numerical_gradient(x, y, W, b)\n",
    "        # assert np.allclose(ngW, dW) and np.allclose(ngb, db)\n",
    "\n",
    "        W += -lr * dW\n",
    "        b += -lr * db\n",
    "\n",
    "        # Train loss\n",
    "        loss_train = loss(y, y_hat)                             # binary cross-entropy\n",
    "        losses.append(loss_train)                               # save for plotting\n",
    "\n",
    "        if e % (nb_epochs / 10) == 0:\n",
    "            print('loss ', loss_train.round(4))\n",
    "            \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, W, b):                                 #                        x.shape (batch_size, nb_inputs)\n",
    "    return sigmoid( x @ W + b )                       #                        shape: (batch_size, nb_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
