{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>TODO: switch from Udacity dataset to publicly available one</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "\n",
    "* [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
    "* [Keras Official Seq2Seq Example](https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "* [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) (2014) by Ilya Sutskever, Oriol Vinyals, Quoc V. Le\n",
    "* [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078) (2014) by Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)  # init TF ...\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)  # w/o taking ...\n",
    "with tf.Session(config=config): pass            # all GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to French Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = '/home/marcin/Udacity/aind2-nlp-capstone/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ST new jersey is sometimes quiet during autumn , and it is snowy in april . EN',\n",
       " 'ST the united states is usually chilly during july , and it is usually freezing in november . EN',\n",
       " 'ST california is usually quiet during march , and it is usually hot in june . EN']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(dataset_location, 'small_vocab_en')) as f:\n",
    "    data_en_raw = list(map(lambda x: 'ST '+x.strip().lower()+' EN', f.readlines()))\n",
    "data_en_raw[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"ST new jersey est parfois calme pendant l' automne , et il est neigeux en avril . EN\",\n",
       " 'ST les états-unis est généralement froid en juillet , et il gèle habituellement en novembre . EN',\n",
       " 'ST california est généralement calme en mars , et il est généralement chaud en juin . EN']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(dataset_location, 'small_vocab_fr')) as f:\n",
    "    data_fr_raw = list(map(lambda x: 'ST '+x.strip().lower()+' EN', f.readlines()))\n",
    "data_fr_raw[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 19, 25, 1, 10, 69, 6, 41, 9, 5, 1, 57, 4, 46, 3],\n",
       " [2, 7, 22, 23, 1, 11, 64, 6, 45, 9, 5, 1, 11, 53, 4, 47, 3],\n",
       " [2, 24, 1, 11, 69, 6, 40, 9, 5, 1, 11, 70, 4, 36, 3]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_en = tf.keras.preprocessing.text.Tokenizer(lower=False)\n",
    "tok_en.fit_on_texts(data_en_raw)\n",
    "data_en_tok = tok_en.texts_to_sequences(data_en_raw)\n",
    "data_en_tok[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 37, 36, 1, 10, 69, 39, 13, 26, 8, 5, 1, 114, 4, 52, 3],\n",
       " [2, 6, 34, 33, 1, 14, 21, 4, 51, 8, 5, 97, 71, 4, 53, 3],\n",
       " [2, 103, 1, 14, 69, 4, 47, 8, 5, 1, 14, 23, 4, 43, 3]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_fr = tf.keras.preprocessing.text.Tokenizer(lower=False)\n",
    "tok_fr.fit_on_texts(data_fr_raw)\n",
    "data_fr_tok = tok_fr.texts_to_sequences(data_fr_raw)\n",
    "data_fr_tok[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_en = len(max(data_en_tok, key=len))\n",
    "max_len_fr = len(max(data_fr_tok, key=len))\n",
    "max_len_both = max(max_len_en, max_len_fr)\n",
    "max_len_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en_tok, maxlen=max_len_en, padding='post')\n",
    "data_fr = tf.keras.preprocessing.sequence.pad_sequences(data_fr_tok, maxlen=max_len_fr, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_en_seq 17\n",
      "n_fr_seq 23\n",
      "n_en_vocab 201\n",
      "n_fr_vocab 346\n",
      "max_seq_len 23\n"
     ]
    }
   ],
   "source": [
    "n_en_seq = data_en.shape[1]\n",
    "n_fr_seq = data_fr.shape[1]\n",
    "n_en_vocab = len(tok_en.word_index)\n",
    "n_fr_vocab = len(tok_fr.word_index)\n",
    "max_seq_len = max(n_en_seq, n_fr_seq)\n",
    "print('n_en_seq', n_en_seq)\n",
    "print('n_fr_seq', n_fr_seq)\n",
    "print('n_en_vocab', n_en_vocab)\n",
    "print('n_fr_vocab', n_fr_vocab)\n",
    "print('max_seq_len', max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137860, 23)\n",
      "[[ 2 19 25  1 10 69  6 41  9  5  1 57  4 46  3  0  0  0  0  0  0  0  0]\n",
      " [ 2  7 22 23  1 11 64  6 45  9  5  1 11 53  4 47  3  0  0  0  0  0  0]\n",
      " [ 2 24  1 11 69  6 40  9  5  1 11 70  4 36  3  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(data_en.shape)\n",
    "print(data_en[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137860, 23)\n",
      "[[  2  37  36   1  10  69  39  13  26   8   5   1 114   4  52   3   0   0\n",
      "    0   0   0   0   0]\n",
      " [  2   6  34  33   1  14  21   4  51   8   5  97  71   4  53   3   0   0\n",
      "    0   0   0   0   0]\n",
      " [  2 103   1  14  69   4  47   8   5   1  14  23   4  43   3   0   0   0\n",
      "    0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(data_fr.shape)\n",
    "print(data_fr[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/rnn_bidirectional.png\"/>\n",
    "<center>Figure from Bidirectional Recurrent Neural Networks (1997) by Mike Schuster and kuldip K. Paliwal</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 23, 50)            10050     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 23, 128)           44160     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 23, 346)           44634     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 23, 346)           0         \n",
      "=================================================================\n",
      "Total params: 98,844\n",
      "Trainable params: 98,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, TimeDistributed, Dense, Activation\n",
    "\n",
    "X_input = Input(shape=(n_en_seq,))\n",
    "X = Embedding(input_dim=n_en_vocab, output_dim=50)(X_input)\n",
    "X = Bidirectional( GRU(units=64, return_sequences=True) )(X)\n",
    "X = TimeDistributed(Dense(units=n_fr_vocab))(X)\n",
    "X = Activation('softmax')(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=X_input, outputs=X)\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcin/.anaconda/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27572 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 10s 92us/step - loss: 3.5588 - sparse_categorical_accuracy: 0.4012 - val_loss: nan - val_sparse_categorical_accuracy: 0.4732\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 9s 78us/step - loss: 2.3705 - sparse_categorical_accuracy: 0.4941 - val_loss: nan - val_sparse_categorical_accuracy: 0.5431\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 9s 77us/step - loss: 1.6129 - sparse_categorical_accuracy: 0.6072 - val_loss: nan - val_sparse_categorical_accuracy: 0.6707\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 9s 77us/step - loss: 1.1627 - sparse_categorical_accuracy: 0.7082 - val_loss: nan - val_sparse_categorical_accuracy: 0.7400\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 9s 78us/step - loss: 0.9342 - sparse_categorical_accuracy: 0.7557 - val_loss: nan - val_sparse_categorical_accuracy: 0.7703\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 8s 77us/step - loss: 0.7899 - sparse_categorical_accuracy: 0.7832 - val_loss: nan - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 9s 78us/step - loss: 0.6844 - sparse_categorical_accuracy: 0.8059 - val_loss: nan - val_sparse_categorical_accuracy: 0.8167\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 9s 78us/step - loss: 0.6039 - sparse_categorical_accuracy: 0.8247 - val_loss: nan - val_sparse_categorical_accuracy: 0.8335\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 9s 79us/step - loss: 0.5409 - sparse_categorical_accuracy: 0.8410 - val_loss: nan - val_sparse_categorical_accuracy: 0.8489\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 9s 79us/step - loss: 0.4906 - sparse_categorical_accuracy: 0.8543 - val_loss: nan - val_sparse_categorical_accuracy: 0.8605\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=data_en, y=np.expand_dims(data_fr, axis=-1),\n",
    "                 batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_english(seq):\n",
    "    words = [tok_en.index_word[x] for x in seq if x in tok_en.index_word]\n",
    "    return ' '.join(words)\n",
    "def sequence_to_french(seq):\n",
    "    words = [tok_fr.index_word[x] for x in seq if x in tok_fr.index_word]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english:             ST we dislike oranges , grapefruit , and bananas . EN\n",
      "french (original):   ST nous détestons les oranges , le pamplemousse et les bananes . EN\n",
      "french (predicted):  ST nous détestons les le le pamplemousse et les les EN\n"
     ]
    }
   ],
   "source": [
    "index = 234\n",
    "english_sentence = data_en_raw[index]\n",
    "french_sentence = data_fr_raw[index]\n",
    "\n",
    "prediction_prob = model.predict(data_en[index:index+1])\n",
    "prediction_prob = prediction_prob.squeeze()\n",
    "prediction_tok = prediction_prob.argmax(axis=-1)\n",
    "predicted_sentence = sequence_to_french(prediction_tok)\n",
    "\n",
    "print('english:            ', english_sentence)\n",
    "print('french (original):  ', french_sentence)\n",
    "print('french (predicted): ', predicted_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137860, 23)\n",
      "[[ 37  36   1  10  69  39  13  26   8   5   1 114   4  52   3   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  6  34  33   1  14  21   4  51   8   5  97  71   4  53   3   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [103   1  14  69   4  47   8   5   1  14  23   4  43   3   0   0   0   0\n",
      "    0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "data_fr_noST = np.roll(data_fr, shift=-1, axis=-1)\n",
    "data_fr_noST[:,-1] = 0\n",
    "print(data_fr_noST.shape)\n",
    "print(data_fr_noST[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Enc_Input (InputLayer)          (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Dec_Target (InputLayer)         (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Enc_Embbeding (Embedding)       (None, 17, 50)       10050       Enc_Input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dec_Embbedingg (Embedding)      (None, 23, 50)       17300       Dec_Target[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Enc_LSTM (LSTM)                 [(None, 512), (None, 1153024     Enc_Embbeding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dec_LSTM (LSTM)                 [(None, 23, 512), (N 1153024     Dec_Embbedingg[0][0]             \n",
      "                                                                 Enc_LSTM[0][1]                   \n",
      "                                                                 Enc_LSTM[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dec_Output (Dense)              (None, 23, 346)      177498      Dec_LSTM[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,510,896\n",
      "Trainable params: 2,510,896\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Activation\n",
    "\n",
    "E_input = Input(shape=(n_en_seq,), name='Enc_Input')\n",
    "E = Embedding(input_dim=n_en_vocab, output_dim=50, name='Enc_Embbeding')(E_input)\n",
    "_, Eh, Ec = LSTM(units=512, return_state=True, name='Enc_LSTM')(E)\n",
    "\n",
    "decoder_embedding = Embedding(input_dim=n_fr_vocab, output_dim=50, name='Dec_Embbedingg')\n",
    "decoder_lstm = LSTM(512, return_sequences=True, return_state=True, name='Dec_LSTM')\n",
    "decoder_dense = Dense(n_fr_vocab, activation='softmax', name='Dec_Output')\n",
    "\n",
    "D_input = Input(shape=(n_fr_seq,), name='Dec_Target')\n",
    "D = decoder_embedding(D_input)\n",
    "D, _, _ = decoder_lstm(D, initial_state=[Eh, Ec])\n",
    "D_output = decoder_dense(D)\n",
    "\n",
    "model = tf.keras.Model(inputs=[E_input, D_input], outputs=D_output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcin/.anaconda/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27572 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 24s 219us/step - loss: 2.8013 - sparse_categorical_accuracy: 0.4601 - val_loss: nan - val_sparse_categorical_accuracy: 0.5576\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 22s 203us/step - loss: 1.6133 - sparse_categorical_accuracy: 0.6177 - val_loss: nan - val_sparse_categorical_accuracy: 0.6952\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 22s 204us/step - loss: 0.8836 - sparse_categorical_accuracy: 0.7342 - val_loss: nan - val_sparse_categorical_accuracy: 0.7608\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 22s 203us/step - loss: 0.7734 - sparse_categorical_accuracy: 0.7541 - val_loss: nan - val_sparse_categorical_accuracy: 0.7796\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 23s 205us/step - loss: 0.6238 - sparse_categorical_accuracy: 0.7892 - val_loss: nan - val_sparse_categorical_accuracy: 0.7961\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 23s 209us/step - loss: 0.5685 - sparse_categorical_accuracy: 0.8029 - val_loss: nan - val_sparse_categorical_accuracy: 0.8112\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 23s 205us/step - loss: 0.5298 - sparse_categorical_accuracy: 0.8162 - val_loss: nan - val_sparse_categorical_accuracy: 0.8272\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 23s 204us/step - loss: 0.4960 - sparse_categorical_accuracy: 0.8285 - val_loss: nan - val_sparse_categorical_accuracy: 0.8297\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 23s 205us/step - loss: 0.4707 - sparse_categorical_accuracy: 0.8369 - val_loss: nan - val_sparse_categorical_accuracy: 0.8408\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 23s 207us/step - loss: 0.4503 - sparse_categorical_accuracy: 0.8434 - val_loss: nan - val_sparse_categorical_accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe65a593f28>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[data_en, data_fr], y=np.expand_dims(data_fr_noST, axis=-1),\n",
    "          batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder and Sampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(inputs=E_input, outputs=[Eh, Ec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Enc_Input (InputLayer)       (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "Enc_Embbeding (Embedding)    (None, 23, 50)            10050     \n",
      "_________________________________________________________________\n",
      "Enc_LSTM (LSTM)              [(None, 512), (None, 512) 1153024   \n",
      "=================================================================\n",
      "Total params: 1,163,074\n",
      "Trainable params: 1,163,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sh_init = Input(shape=(512,))\n",
    "Sc_init = Input(shape=(512,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sam_Input:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_input = Input(shape=(1,), name='Sam_Input')\n",
    "S_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Dec_Embbedingg_1/embedding_lookup/Identity_2:0' shape=(?, 1, 50) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = decoder_embedding(S_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, Sh, Sc = decoder_lstm(S, initial_state=[Sh_init, Sc_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_output = decoder_dense(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = tf.keras.Model(inputs=[S_input, Sh_init, Sc_init], outputs=[S_output, Sh, Sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Sam_Input (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Dec_Embbedingg (Embedding)      multiple             17300       Sam_Input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Dec_LSTM (LSTM)                 multiple             1153024     Dec_Embbedingg[1][0]             \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Dec_Output (Dense)              multiple             177498      Dec_LSTM[1][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,347,822\n",
      "Trainable params: 1,347,822\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sampler.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english:             ST his least favorite fruit is the pear , but our least favorite is the banana . EN\n",
      "french (original):   ST son fruit préféré est moins la poire , mais notre moins préféré est la banane . EN\n"
     ]
    }
   ],
   "source": [
    "index = 666\n",
    "english_sentence = data_en_raw[index]\n",
    "french_sentence = data_fr_raw[index]\n",
    "print('english:            ', english_sentence)\n",
    "print('french (original):  ', french_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actually Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_h, st_c = encoder.predict(data_en[index:index+1])\n",
    "assert st_h.shape == (1, 512) and st_c.shape == (1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_input = tok_fr.word_index['ST']\n",
    "st_input = np.array([[st_input]])  # batch size = 1, seq len = 1\n",
    "assert st_input.shape == (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tok = []\n",
    "for i in range(n_fr_seq):\n",
    "    probs, st_h, st_c = sampler.predict([st_input, st_h, st_c])\n",
    "    assert st_h.shape == (1, 512) and st_c.shape == (1, 512)\n",
    "    \n",
    "    st_input = probs.argmax(axis=-1)\n",
    "    assert st_input.shape == (1, 1)\n",
    "    \n",
    "    token = probs.argmax()\n",
    "    prediction_tok.append(token)\n",
    "    \n",
    "    if token == tok_fr.word_index['EN']:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 18, 19, 1, 15, 9, 90, 7, 22, 15, 19, 1, 9, 91, 3]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english:             ST his least favorite fruit is the pear , but our least favorite is the banana . EN\n",
      "french (original):   ST son fruit préféré est moins la poire , mais notre moins préféré est la banane . EN\n",
      "french (predicted):  son fruit préféré est moins la poire mais son moins préféré est la fraise EN\n"
     ]
    }
   ],
   "source": [
    "print('english:            ', english_sentence)\n",
    "print('french (original):  ', french_sentence)\n",
    "predicted_sentence = sequence_to_french(prediction_tok)\n",
    "print('french (predicted): ', predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
