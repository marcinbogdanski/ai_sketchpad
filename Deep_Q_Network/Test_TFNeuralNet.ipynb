{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create bowl function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowl_funct(x, y):\n",
    "    return np.tanh( np.sqrt((4*x)**2 + (4*y)**2) -2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = -1, 1\n",
    "y_min, y_max = -1, 1\n",
    "\n",
    "x_space = np.linspace(x_min, x_max, num=100)\n",
    "y_space = np.linspace(y_min, y_max, num=100)\n",
    "\n",
    "Y, X = np.meshgrid(y_space, x_space)\n",
    "Z = bowl_funct(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "axis.plot_wireframe(X, Y, Z)\n",
    "axis.set_xlabel('x')\n",
    "axis.set_ylabel('y')\n",
    "axis.set_zlabel('z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.stack([X.flatten(), Y.flatten()], axis=1)  # shape [10000, 2]\n",
    "train_y = np.array(bowl_funct(train_x[:,0], train_x[:,1]), ndmin=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_x.shape', train_x.shape)\n",
    "print('train_y.shape', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data_x, data_y):\n",
    "    assert data_x.ndim == 2 and data_x.shape[1] == 2\n",
    "    assert data_y.ndim == 2 and data_y.shape[1] == 1\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    axis = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    axis.scatter3D(data_x[:,0], data_x[:,1], data_y, marker='.', alpha=.05)\n",
    "    axis.set_xlabel('x')\n",
    "    axis.set_ylabel('y')\n",
    "    axis.set_zlabel('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data_x, data_y, axis=None):\n",
    "    assert data_x.ndim == 2 and data_x.shape[1] == 2\n",
    "    assert data_y.ndim == 2 and data_y.shape[1] == 1\n",
    "    \n",
    "    if axis is None:\n",
    "        fig = plt.figure(figsize=[12,9])\n",
    "        axis = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    X = data_x[:,0].reshape([100, 100])\n",
    "    Y = data_x[:,1].reshape([100, 100])\n",
    "    Z = data_y.reshape([100,100])\n",
    "\n",
    "    axis.plot_wireframe(X, Y, Z)\n",
    "    axis.set_xlabel('x')\n",
    "    axis.set_ylabel('y')\n",
    "    axis.set_zlabel('z')\n",
    "    \n",
    "    # axis.view_init(30, -85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funct Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFFunctApprox():\n",
    "    def __init__(self, nb_in, nb_hid_1, nb_hid_2, nb_out):\n",
    "\n",
    "        # TF model\n",
    "        assert nb_in == 2\n",
    "        assert nb_hid_1 == 256\n",
    "        assert nb_hid_2 == 256\n",
    "        assert nb_out == 1\n",
    "        \n",
    "        self.trace = collections.defaultdict(list)\n",
    "        \n",
    "        try:    sess.close()\n",
    "        except: pass\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self._x = tf.placeholder(name='x', shape=[None, nb_in], dtype=tf.float32)\n",
    "        self._y = tf.placeholder(name='y', shape=[None, nb_out], dtype=tf.float32)\n",
    "\n",
    "        with tf.variable_scope('Hidden_1'):\n",
    "            self._W_hid_1 = tf.get_variable('W_hid_1', shape=[nb_in, nb_hid_1], dtype=tf.float32)\n",
    "            self._b_hid_1 = tf.get_variable('b_hid_1', shape=[nb_hid_1], dtype=tf.float32,\n",
    "                                            initializer=tf.zeros_initializer())\n",
    "            self._z_hid_1 = tf.matmul(self._x, self._W_hid_1) + self._b_hid_1\n",
    "            self._h_hid_1 = tf.nn.relu(self._z_hid_1)\n",
    "\n",
    "        with tf.variable_scope('Hidden_2'):\n",
    "            self._W_hid_2 = tf.get_variable('W_hid_2', shape=[nb_hid_1, nb_hid_2], dtype=tf.float32)\n",
    "            self._b_hid_2 = tf.get_variable('b_hid_2', shape=[nb_hid_2], dtype=tf.float32,\n",
    "                                           initializer=tf.zeros_initializer())\n",
    "            self._z_hid_2 = tf.matmul(self._h_hid_1, self._W_hid_2) + self._b_hid_2\n",
    "            self._h_hid_2 = tf.nn.relu(self._z_hid_2)\n",
    "\n",
    "        with tf.variable_scope('Output'):\n",
    "            self._W_out = tf.get_variable('W_out', shape=[nb_hid_2, nb_out], dtype=tf.float32)\n",
    "            self._b_out = tf.get_variable('b_out', shape=[nb_out],\n",
    "                                         initializer=tf.zeros_initializer())\n",
    "            self._y_hat = tf.matmul(self._h_hid_2, self._W_out) + self._b_out\n",
    "\n",
    "        with tf.variable_scope('MSE'):\n",
    "            self._mse = tf.reduce_mean( tf.pow(self._y - self._y_hat, 2) )\n",
    "\n",
    "        self._optimizer = tf.train.RMSPropOptimizer(learning_rate=0.00025)\n",
    "        #self._optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.025)\n",
    "        grads_and_vars = self._optimizer.compute_gradients(self._mse)\n",
    "        self._train_op = self._optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "        self._dW_hid_1 = grads_and_vars[0][0]\n",
    "        self._db_hid_1 = grads_and_vars[1][0]\n",
    "        self._dW_hid_2 = grads_and_vars[2][0]\n",
    "        self._db_hid_2 = grads_and_vars[3][0]\n",
    "        self._dW_out = grads_and_vars[4][0]\n",
    "        self._db_out = grads_and_vars[5][0]\n",
    "        \n",
    "        self._sess = tf.Session()\n",
    "        self._sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def backward(self, x, y):\n",
    "        _, y_hat, z_hid_2, z_hid_1, loss, \\\n",
    "            dW_hid_1, db_hid_1, dW_hid_2, db_hid_2, dW_out, db_out = self._sess.run(\n",
    "                [self._train_op, self._y_hat, self._z_hid_2, self._z_hid_1, self._mse,\n",
    "                self._dW_hid_1, self._db_hid_1, self._dW_hid_2, self._db_hid_2, self._dW_out, self._db_out],\n",
    "                feed_dict={self._x: x, self._y:y})\n",
    "        \n",
    "        self.trace['loss'].append(loss)\n",
    "        self.trace['z_hid_1'].append(z_hid_1)\n",
    "        self.trace['z_hid_2'].append(z_hid_2)\n",
    "        self.trace['z_out'].append(y_hat)\n",
    "        \n",
    "        self.trace['dW_hid_1'].append(dW_hid_1)\n",
    "        self.trace['db_hid_1'].append(db_hid_1)\n",
    "        self.trace['dW_hid_2'].append(dW_hid_2)\n",
    "        self.trace['db_hid_2'].append(db_hid_2)\n",
    "        self.trace['dW_out'].append(dW_out)\n",
    "        self.trace['db_out'].append(db_out)\n",
    "        \n",
    "        W_hid_1, b_hid_1, W_hid_2, b_hid_2, W_out, b_out = self._sess.run(tf.trainable_variables())\n",
    "        self.trace['W_hid_1'].append(W_hid_1)\n",
    "        self.trace['b_hid_1'].append(b_hid_1)\n",
    "        self.trace['W_hid_2'].append(W_hid_2)\n",
    "        self.trace['b_hid_2'].append(b_hid_2)\n",
    "        self.trace['W_out'].append(W_out)\n",
    "        self.trace['b_out'].append(b_out)\n",
    "        \n",
    "        return y_hat, loss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._sess.run(self._y_hat, feed_dict={self._x: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_in = 196   # 784\n",
    "# n_hid = 128  # 128             # try 8, 128(def.), 2048\n",
    "# n_out = 10\n",
    "# lr = .03     # 0.03                # try 10, 1(best), 0.03, 0.0003\n",
    "\n",
    "n_batch = 100\n",
    "act_fun = 'relu'\n",
    "completed_epochs = 0\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# Initialize weights\n",
    "# var_hid = np.sqrt(1/n_in)             # try:  0.001,  sqrt(1/n_in),  1\n",
    "# var_out = np.sqrt(1/n_hid)\n",
    "# W_hid = np.random.normal(0.0, var_hid, [n_in, n_hid])\n",
    "# W_out = np.random.normal(0.0, var_out, [n_hid, n_out])\n",
    "\n",
    "app = TFFunctApprox(nb_in=2,\n",
    "                    nb_hid_1=256,\n",
    "                    nb_hid_2=256,\n",
    "                    nb_out=1)\n",
    "writer = tf.summary.FileWriter(logdir='tf_log', graph=app._sess.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = app.forward(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[12,6])\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "plot_data(train_x, train_y, ax1)\n",
    "plot_data(train_x, app.forward(train_x), ax2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ti_ = 0\n",
    "train_i = np.array(range(len(train_x)))\n",
    "for e in range(10):\n",
    "    print(e)\n",
    "    \n",
    "    if e % 1 == 0:\n",
    "        fig = plt.figure(figsize=[12,3])\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        plot_data(train_x, train_y, ax1)\n",
    "        plot_data(train_x, app.forward(train_x), ax2)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    np.random.shuffle(train_i)\n",
    "    \n",
    "    for i in range(0, len(train_x), n_batch):\n",
    "\n",
    "        # Get 128 sized batch, both as 2d arrays   \n",
    "        batch = train_i[i:i+n_batch]\n",
    "        x = train_x[batch]\n",
    "        y = train_y[batch]\n",
    "        \n",
    "        y_hat, loss = app.backward(x, y)\n",
    "\n",
    "        assert y_hat.shape == y.shape\n",
    "        assert np.isscalar(loss)\n",
    "\n",
    "        ti_ += 1\n",
    "        \n",
    "    completed_epochs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss = np.array(app.trace['loss'])\n",
    "print('tr_loss', tr_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Plot Loss, Accuracy\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=[12,6])\n",
    "ax.plot(tr_loss, label='Mini-Batch loss', alpha=.5)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Weight Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Debug_NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotann\n",
    "import importlib\n",
    "importlib.reload(plotann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_W_hid_1 = np.array(app.trace['W_hid_1'])\n",
    "tr_b_hid_1 = np.array(app.trace['b_hid_1'])\n",
    "tr_W_hid_2 = np.array(app.trace['W_hid_2'])\n",
    "tr_b_hid_2 = np.array(app.trace['b_hid_2'])\n",
    "tr_W_out = np.array(app.trace['W_out'])\n",
    "tr_b_out = np.array(app.trace['b_out'])\n",
    "\n",
    "tr_dW_hid_1 = np.array(app.trace['dW_hid_1'])\n",
    "tr_db_hid_1 = np.array(app.trace['db_hid_1'])\n",
    "tr_dW_hid_2 = np.array(app.trace['dW_hid_2'])\n",
    "tr_db_hid_2 = np.array(app.trace['db_hid_2'])\n",
    "tr_dW_out = np.array(app.trace['dW_out'])\n",
    "tr_db_out = np.array(app.trace['db_out'])\n",
    "\n",
    "print('tr_W_hid_1', tr_W_hid_1.shape, tr_W_hid_1.size/1e6)\n",
    "print('tr_b_hid_1', tr_b_hid_1.shape, tr_b_hid_1.size/1e6)\n",
    "print('tr_W_hid_2', tr_W_hid_2.shape, tr_W_hid_2.size/1e6)\n",
    "print('tr_b_hid_2', tr_b_hid_2.shape, tr_b_hid_2.size/1e6)\n",
    "print('tr_W_out', tr_W_out.shape, tr_W_out.size/1e6)\n",
    "print('tr_b_out', tr_b_out.shape, tr_b_out.size/1e6)\n",
    "\n",
    "print('tr_dW_hid_1', tr_dW_hid_1.shape, tr_W_hid_1.size/1e6)\n",
    "print('tr_db_hid_1', tr_db_hid_1.shape, tr_b_hid_1.size/1e6)\n",
    "print('tr_dW_hid_2', tr_dW_hid_2.shape, tr_W_hid_2.size/1e6)\n",
    "print('tr_db_hid_2', tr_db_hid_2.shape, tr_b_hid_2.size/1e6)\n",
    "print('tr_dW_out', tr_dW_out.shape, tr_W_out.size/1e6)\n",
    "print('tr_db_out', tr_db_out.shape, tr_b_out.size/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_z_hid_1 = np.array(app.trace['z_hid_1'])\n",
    "tr_z_hid_2 = np.array(app.trace['z_hid_2'])\n",
    "tr_z_out = np.array(app.trace['z_out'])\n",
    "print('tr_z_hid_1', tr_z_hid_1.shape, tr_z_hid_1.size/1e6)\n",
    "print('tr_z_hid_2', tr_z_hid_2.shape, tr_z_hid_2.size/1e6)\n",
    "print('tr_z_out', tr_z_out.shape, tr_z_out.size/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_neurons_weights(tr_W_hid_1, tr_dW_hid_1, neurons=range(3),\n",
    "                            title_prefix='Hidden_1', color='red', figsize=[16,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_biases(tr_b_hid_1+1e-6, tr_db_hid_1, title_prefix='Biases_1', color='red', figsize=[16,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_layer_summary(tr_W_hid_1, tr_dW_hid_1, title_prefix='Hidden_1', color='red', figsize=[16,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 10000  # epoch_size\n",
    "plotann.show_layer_activations(tr_z_hid_1, epoch_size=es, activation_function=act_fun,\n",
    "                               title_prefix='Hidden_1', color=(1,0,0,1), figsize=[16,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 10000  # epoch_size\n",
    "plotann.show_neurons_activations(tr_z_hid_1, epoch_size=es, activation_function=act_fun, neurons=range(10),\n",
    "                                 title_prefix='Hidden_1', color=(1,0,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_neurons_weights(tr_W_hid_2, tr_dW_hid_2, neurons=range(3),\n",
    "                            title_prefix='Hidden_2', color='green', figsize=[16,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_biases(tr_b_hid_2+1e-6, tr_db_hid_2, title_prefix='Biases_2', color='green', figsize=[16,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_layer_summary(tr_W_hid_2, tr_dW_hid_2, title_prefix='Hidden_2', color='green', figsize=[16,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 10000  # epoch_size\n",
    "plotann.show_layer_activations(tr_z_hid_2, epoch_size=es, activation_function=act_fun,\n",
    "                               title_prefix='Hidden_2', color=(0,1,0,1), figsize=[16,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 10000  # epoch_size\n",
    "plotann.show_neurons_activations(tr_z_hid_2, epoch_size=es, activation_function=act_fun, neurons=range(10),\n",
    "                                 title_prefix='Hidden_2', color=(0,1,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_neurons_weights(tr_W_out, tr_dW_out, neurons=range(1),\n",
    "                             title_prefix='Output', color='blue', figsize=[16,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_biases(tr_b_out+1e-6, tr_db_out, title_prefix='Bisases_Output', color='blue', figsize=[16,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotann.show_layer_summary(tr_W_out, tr_dW_out, title_prefix='Output', color='blue', figsize=[16,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 10000  # epoch_size\n",
    "plotann.show_layer_activations(tr_z_out, epoch_size=es, activation_function=act_fun,\n",
    "                               title_prefix='Output', color=(0,0,1,1), figsize=[16,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 10000  # epoch_size\n",
    "plotann.show_neurons_activations(tr_z_out, epoch_size=es, activation_function=act_fun, neurons=range(tr_z_out.shape[-1]),\n",
    "                                 title_prefix='Output', color=(0,0,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
