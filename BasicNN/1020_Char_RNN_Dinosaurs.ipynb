{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset originaly obtained from https://github.com/suarasaur/dinosaurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aachenosaurus', 'aardonyx', 'abelisaurus', 'abrictosaurus']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dinosaurs.csv') as f:\n",
    "    data = [x.strip() for x in f.readlines()]\n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(''.join(data)))               # ['x', 'z', 'j', 'g', ... ]\n",
    "chars.insert(0, ' ')                           # use space as not-a-char tag, used for padding\n",
    "ch2i = {ch:i for i,ch in enumerate(chars)}     # {' ': 0, 'x': 1, 'z': 2, 'j': 3, 'g': 4, ... }\n",
    "i2ch = {i:ch for ch,i in ch2i.items()}         # {0: ' ', 1: 'x', 2: 'z', 3: 'j', 4: 'g', ... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yongjinglong', 'eocarcharia', 'shidaisaurus', 'brasileosaurus']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "np.random.shuffle(data)\n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yongjinglong           ',\n",
       " 'eocarcharia            ',\n",
       " 'shidaisaurus           ',\n",
       " 'brasileosaurus         ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(data, key=len))  # length of longest dino name\n",
    "for i, dino in enumerate(data):\n",
    "    data[i] = dino.ljust(max_len)  # pad all names with spaces to same length\n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 13, 11, 6, 22, 11, 4, 26, 10, 17]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[ch2i[x] for x in dino]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.zeros(shape=[len(data), max_len], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dino_name in enumerate(data):\n",
    "    indices[i] = [ch2i[x] for x in dino_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inosaurus              '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inosaurus              '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([i2ch[x] for x in indices[234]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = np.zeros(shape=[len(data), max_len, vocab_size], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    for j in range(max_len):\n",
    "        onehot[i, j, indices[i,j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inosaurus              '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([i2ch[np.argmax(x)] for x in onehot[234]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325, 23, 27)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Udacity_DL_Nanodegree/031%20RNN%20Super%20Basics/MultiMultiRNN01.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/rnn_diag.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperbolic Tangent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_der(x):\n",
    "    return 1.0 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see e.g. here: https://deepnotes.io/softmax-crossentropy\n",
    "def softmax(x):\n",
    "    \"\"\"Numerically stable softmax\"\"\"\n",
    "    max_ = np.max(x, axis=-1, keepdims=True)       #                  shape: (n_batch, 1)\n",
    "    ex = np.exp(x - max_)                          #                  shape: (n_batch, n_out)\n",
    "    ex_sum = np.sum(ex, axis=-1, keepdims=True)    #                  shape: (n_batch, 1)\n",
    "    return ex / ex_sum                             # probabilities    shape: (n_batch, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, y_hat):\n",
    "    \"\"\"CE for one-hot targets y, averages over batch.\"\"\"\n",
    "    assert np.alltrue(y.sum(axis=-1) == 1)                          # make sure y is one-hot encoded\n",
    "    assert np.alltrue(y.max(axis=-1) == 1)\n",
    "    prob_correct = y_hat[range(len(y_hat)), np.argmax(y, axis=-1)]  # pick y_hat for correct class       (n_batch,)\n",
    "    return np.average( -np.log(prob_correct) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, Wxh, Whh, Who):\n",
    "    assert x.ndim==3 and x.shape[1:]==(4, 3)\n",
    "    \n",
    "    x_t = {}\n",
    "    s_t = {}\n",
    "    z_t = {}\n",
    "    s_t[-1] = np.zeros([len(x), len(Whh)])   # [n_batch, n_hid]\n",
    "    T = x.shape[1]\n",
    "    \n",
    "    for t in range(T):\n",
    "        x_t[t] = x[:,t,:]\n",
    "        z_t[t] = s_t[t-1] @ Whh + x_t[t] @ Wxh\n",
    "        s_t[t] = tanh(z_t[t])\n",
    "    \n",
    "    z_out = s_t[t] @ Who\n",
    "    y_hat = softmax( z_out )\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(x, y, Wxh, Whh, Who):\n",
    "    assert x.ndim==3 and x.shape[1:]==(4, 3)\n",
    "    assert y.ndim==2 and y.shape[1:]==(1,)\n",
    "    assert len(x) == len(y)\n",
    "    \n",
    "    # Init\n",
    "    x_t = {}\n",
    "    s_t = {}\n",
    "    z_t = {}\n",
    "    s_t[-1] = np.zeros([len(x), len(Whh)])   # [n_batch, n_hid]\n",
    "    T = x.shape[1]\n",
    "        \n",
    "    # Forward\n",
    "    for t in range(T):                                  # t = [0, 1, 2, 3]\n",
    "        x_t[t] = x[:,t,:]                               # pick time-step input          x_[t].shape = (n_batch, n_in)\n",
    "        z_t[t] = s_t[t-1] @ Whh + x_t[t] @ Wxh\n",
    "        s_t[t] = tanh(z_t[t])\n",
    "    z_out = s_t[t] @ Who\n",
    "    y_hat = softmax( z_out )\n",
    "    \n",
    "    # Backward\n",
    "    dWxh = np.zeros_like(Wxh)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWho = np.zeros_like(Who)\n",
    "    \n",
    "    ro = y_hat - y                                      # Backprop through loss funt.\n",
    "    dWho = s_t[t].T @ ro                                # \n",
    "    ro = ro @ Who.T * tanh_der(z_t[t])                  # Backprop into hidden state\n",
    "    \n",
    "    for t in reversed(range(T)):                        # t = [3, 2, 1, 0]\n",
    "        dWxh += x_t[t].T @ ro\n",
    "        dWhh += s_t[t-1].T @ ro\n",
    "        if t != 0:                                      # don't backprop into t=-1\n",
    "            ro = ro @ Whh.T * tanh_der(z_t[t-1])        # Backprop into previous time step\n",
    "    \n",
    "    return y_hat, dWxh, dWhh, dWho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(x, y, nb_epochs, learning_rate, Wxh, Whh, Who):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        \n",
    "        y_hat, dWxh, dWhh, dWho = backward(x, y, Wxh, Whh, Who)\n",
    "        \n",
    "        Wxh += -learning_rate * dWxh\n",
    "        Whh += -learning_rate * dWhh\n",
    "        Who += -learning_rate * dWho\n",
    "        \n",
    "        # Log and print\n",
    "        loss_train = mse(x, y, Wxh, Whh, Who)\n",
    "        losses.append(loss_train)\n",
    "        if e % (nb_epochs / 10) == 0:\n",
    "            print('loss ', loss_train.round(4))\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(x, y, Wxh, Whh, Who):\n",
    "    dWxh = np.zeros_like(Wxh)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWho = np.zeros_like(Who)\n",
    "    eps = 1e-4\n",
    "    \n",
    "    for r in range(len(Wxh)):\n",
    "        for c in range(Wxh.shape[1]):\n",
    "            Wxh_pls = Wxh.copy()\n",
    "            Wxh_min = Wxh.copy()\n",
    "            \n",
    "            Wxh_pls[r, c] += eps\n",
    "            Wxh_min[r, c] -= eps\n",
    "            \n",
    "            l_pls = mse(x, y, Wxh_pls, Whh, Who)\n",
    "            l_min = mse(x, y, Wxh_min, Whh, Who)\n",
    "            \n",
    "            dWxh[r, c] = (l_pls - l_min) / (2*eps)\n",
    "    \n",
    "    for r in range(len(Whh)):\n",
    "        for c in range(Whh.shape[1]):\n",
    "            Whh_pls = Whh.copy()\n",
    "            Whh_min = Whh.copy()\n",
    "            \n",
    "            Whh_pls[r, c] += eps\n",
    "            Whh_min[r, c] -= eps\n",
    "            \n",
    "            l_pls = mse(x, y, Wxh, Whh_pls, Who)\n",
    "            l_min = mse(x, y, Wxh, Whh_min, Who)\n",
    "            \n",
    "            dWhh[r, c] = (l_pls - l_min) / (2*eps)\n",
    "    \n",
    "    for r in range(len(Who)):\n",
    "        for c in range(Who.shape[1]):\n",
    "            Who_pls = Who.copy()\n",
    "            Who_min = Who.copy()\n",
    "            \n",
    "            Who_pls[r, c] += eps\n",
    "            Who_min[r, c] -= eps\n",
    "            \n",
    "            l_pls = mse(x, y, Wxh, Whh, Who_pls)\n",
    "            l_min = mse(x, y, Wxh, Whh, Who_min)\n",
    "            \n",
    "            dWho[r, c] = (l_pls - l_min) / (2*eps)\n",
    "    \n",
    "    \n",
    "    return dWxh, dWhh, dWho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
