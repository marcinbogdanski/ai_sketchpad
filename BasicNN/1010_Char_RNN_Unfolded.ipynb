{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Udacity_DL_Nanodegree/031%20RNN%20Super%20Basics/SimpleRNN01.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sigmoid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperbolic Tangent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_der(x):\n",
    "    return 1.0 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x, y, Wxh, Whh, Who):\n",
    "    y_hat = forward(x, Wxh, Whh, Who)\n",
    "    return 0.5 * np.mean((y-y_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, Wxh, Whh, Who):\n",
    "    assert x.ndim==3 and x.shape[1:]==(4, 3)\n",
    "    \n",
    "    x_t0 = x[:,0,:]\n",
    "    x_t1 = x[:,1,:]\n",
    "    x_t2 = x[:,2,:]\n",
    "    x_t3 = x[:,3,:]\n",
    "        \n",
    "    s_init = np.zeros([len(x), len(Whh)])   # [n_batch, n_hid]\n",
    "    z_t0 = s_init @ Whh + x_t0 @ Wxh\n",
    "    s_t0 = tanh(z_t0)\n",
    "    z_t1 = s_t0 @ Whh + x_t1 @ Wxh\n",
    "    s_t1 = tanh(z_t1)\n",
    "    z_t2 = s_t1 @ Whh + x_t2 @ Wxh\n",
    "    s_t2 = tanh(z_t2)\n",
    "    z_t3 = s_t2 @ Whh + x_t3 @ Wxh\n",
    "    s_t3 = tanh(z_t3)\n",
    "    z_out = s_t3 @ Who\n",
    "    y_hat = sigmoid( z_out )\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, Wxh, Whh, Who):\n",
    "    assert x.ndim==3 and x.shape[1:]==(4, 3)\n",
    "    \n",
    "    x_t = {}\n",
    "    s_t = {}\n",
    "    z_t = {}\n",
    "    s_t[-1] = np.zeros([len(x), len(Whh)])   # [n_batch, n_hid]\n",
    "    T = x.shape[1]\n",
    "    \n",
    "    for t in range(T):\n",
    "        x_t[t] = x[:,t,:]\n",
    "        z_t[t] = s_t[t-1] @ Whh + x_t[t] @ Wxh\n",
    "        s_t[t] = tanh(z_t[t])\n",
    "    \n",
    "    z_out = s_t[t] @ Who\n",
    "    y_hat = sigmoid( z_out )\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, y, Wxh, Whh, Who):\n",
    "    assert x.ndim==3 and x.shape[1:]==(4, 3)\n",
    "    assert y.ndim==2 and y.shape[1:]==(1,)\n",
    "    assert len(x) == len(y)\n",
    "    \n",
    "    # Forward\n",
    "    x_t0 = x[:,0,:]\n",
    "    x_t1 = x[:,1,:]\n",
    "    x_t2 = x[:,2,:]\n",
    "    x_t3 = x[:,3,:]\n",
    "        \n",
    "    s_init = np.zeros([len(x), len(Whh)])   # [n_batch, n_hid]\n",
    "    z_t0 = s_init @ Whh + x_t0 @ Wxh\n",
    "    s_t0 = tanh(z_t0)\n",
    "    z_t1 = s_t0 @ Whh + x_t1 @ Wxh\n",
    "    s_t1 = tanh(z_t1)\n",
    "    z_t2 = s_t1 @ Whh + x_t2 @ Wxh\n",
    "    s_t2 = tanh(z_t2)\n",
    "    z_t3 = s_t2 @ Whh + x_t3 @ Wxh\n",
    "    s_t3 = tanh(z_t3)\n",
    "    z_out = s_t3 @ Who\n",
    "    y_hat = sigmoid( z_out )\n",
    "    \n",
    "    # Backward\n",
    "    dWxh = np.zeros_like(Wxh)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWho = np.zeros_like(Who)\n",
    "    \n",
    "    err = -(y-y_hat)/len(x) * sigmoid_der( z_out )\n",
    "    dWho = s_t3.T @ err\n",
    "    ro_t3 = err @ Who.T * tanh_der(z_t3)\n",
    "    \n",
    "    dWxh += x_t3.T @ ro_t3\n",
    "    dWhh += s_t2.T @ ro_t3\n",
    "    ro_t2 = ro_t3 @ Whh.T * tanh_der(z_t2)\n",
    "    \n",
    "    dWxh += x_t2.T @ ro_t2\n",
    "    dWhh += s_t1.T @ ro_t2\n",
    "    ro_t1 = ro_t2 @ Whh.T * tanh_der(z_t1)\n",
    "    \n",
    "    dWxh += x_t1.T @ ro_t1\n",
    "    dWhh += s_t0.T @ ro_t1\n",
    "    ro_t0 = ro_t1 @ Whh.T * tanh_der(z_t0)\n",
    "    \n",
    "    dWxh += x_t0.T @ ro_t0\n",
    "    dWhh += s_init.T @ ro_t0\n",
    "    \n",
    "    return y_hat, dWxh, dWhh, dWho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, y, Wxh, Whh, Who):\n",
    "    assert x.ndim==3 and x.shape[1:]==(4, 3)\n",
    "    assert y.ndim==2 and y.shape[1:]==(1,)\n",
    "    assert len(x) == len(y)\n",
    "    \n",
    "    # Init\n",
    "    x_t = {}\n",
    "    s_t = {}\n",
    "    z_t = {}\n",
    "    s_t[-1] = np.zeros([len(x), len(Whh)])   # [n_batch, n_hid]\n",
    "    T = x.shape[1]\n",
    "        \n",
    "    # Forward\n",
    "    for t in range(T):                                  # t = [0, 1, 2, 3]\n",
    "        x_t[t] = x[:,t,:]                               # pick time-step input          x_[t].shape = (n_batch, n_in)\n",
    "        z_t[t] = s_t[t-1] @ Whh + x_t[t] @ Wxh\n",
    "        s_t[t] = tanh(z_t[t])\n",
    "    z_out = s_t[t] @ Who\n",
    "    y_hat = sigmoid( z_out )\n",
    "    \n",
    "    # Backward\n",
    "    dWxh = np.zeros_like(Wxh)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWho = np.zeros_like(Who)\n",
    "    \n",
    "    ro = -(y-y_hat)/len(x) * sigmoid_der( z_out )       # Backprop through loss funt.\n",
    "    dWho = s_t[t].T @ ro                                # \n",
    "    ro = ro @ Who.T * tanh_der(z_t[t])                  # Backprop into hidden state\n",
    "    \n",
    "    for t in reversed(range(T)):                        # t = [3, 2, 1, 0]\n",
    "        dWxh += x_t[t].T @ ro\n",
    "        dWhh += s_t[t-1].T @ ro\n",
    "        if t != 0:                                      # don't backprop into t=-1\n",
    "            ro = ro @ Whh.T * tanh_der(z_t[t-1])        # Backprop into previous time step\n",
    "    \n",
    "    return y_hat, dWxh, dWhh, dWho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(x, y, nb_epochs, learning_rate, Wxh, Whh, Who):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        \n",
    "        y_hat, dWxh, dWhh, dWho = backward(x, y, Wxh, Whh, Who)\n",
    "        \n",
    "        Wxh += -learning_rate * dWxh\n",
    "        Whh += -learning_rate * dWhh\n",
    "        Who += -learning_rate * dWho\n",
    "        \n",
    "        # Log and print\n",
    "        loss_train = mse(x, y, Wxh, Whh, Who)\n",
    "        losses.append(loss_train)\n",
    "        if e % (nb_epochs / 10) == 0:\n",
    "            print('loss ', loss_train.round(4))\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Count Letter 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding: 'a'=[0,0,1] 'b'=[0,1,0] 'c'=[1,0,0]\n",
    "\n",
    "#                            < ----- 4x time steps ----- >\n",
    "x_train = np.array([    \n",
    "                    [ [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0] ],  #  'bbcb'\n",
    "                    [ [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0] ],  #  'cbcb'   ^\n",
    "                    [ [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0] ],  #  'bcbc'   ^\n",
    "                    [ [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0] ],  #  'cbbc'   ^\n",
    "                    [ [1, 0, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0] ],  #  'ccbc'   ^\n",
    "    \n",
    "    \n",
    "                    [ [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0] ],  #  'bacb'   | 9x batch size\n",
    "                    [ [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1] ],  #  'ccba'   v\n",
    "                    [ [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0] ],  #  'acbc'   ^\n",
    "                    [ [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0] ],  #  'cbac'   ^\n",
    "                    \n",
    "                    [ [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0] ],  #  'baab'\n",
    "                    [ [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0] ],  #  'aabc'\n",
    "    \n",
    "                    [ [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1] ],  #  'acaa'\n",
    "                   ])\n",
    "y_train = np.array([ [0],   # <->  no timesteps\n",
    "                     [0],   #\n",
    "                     [0],   #\n",
    "                     [0],   #\n",
    "                     [0],   #\n",
    "                    \n",
    "                     [1],   #  ^\n",
    "                     [1],   #  |  9x batch size\n",
    "                     [1],   #  ^\n",
    "                     [1],   #  |  9x batch size\n",
    "                    \n",
    "                     [0],   #  v\n",
    "                     [0],   #\n",
    "                    \n",
    "                     [1] ]) #\n",
    "x_test = np.array([\n",
    "                   [ [0,1,0], [1,0,0], [1,0,0], [0,1,0] ],  #  'bccb' -> 0\n",
    "                   [ [1,0,0], [1,0,0], [0,1,0], [1,0,0] ],  #  'ccbb' -> 0\n",
    "                   [ [0,1,0], [1,0,0], [0,0,1], [1,0,0] ],  #  'bcac' -> 1\n",
    "                   [ [0,1,0], [0,0,1], [1,0,0], [0,1,0] ],  #  'bacb' -> 1\n",
    "                  ])\n",
    "y_test = np.array([ [0],   # <->  no timesteps\n",
    "                    [0],   #\n",
    "                    [1],   #\n",
    "                    [1], ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "W_xh = 0.1 * np.random.randn(3, 2)  # Wxh.shape: [n_in, n_hid]\n",
    "W_hh = 0.1 * np.random.randn(2, 2)  # Whh.shape: [n_hid, n_hid]\n",
    "W_ho = 0.1 * np.random.randn(2, 1)  # Who.shape: [n_hid, n_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  0.1261\n",
      "loss  0.1247\n",
      "loss  0.1212\n",
      "loss  0.1057\n",
      "loss  0.0891\n",
      "loss  0.0766\n",
      "loss  0.0651\n",
      "loss  0.0468\n",
      "loss  0.0216\n",
      "loss  0.0092\n"
     ]
    }
   ],
   "source": [
    "losses = train_rnn(x_train, y_train, 3000, 0.1, W_xh, W_hh, W_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = forward(x_train, W_xh, W_hh, W_ho).round(0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = forward(x_test, W_xh, W_hh, W_ho).round(0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f17a7fba8>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerical_gradient(x, y, Wxh, Whh, Who):\n",
    "    dWxh = np.zeros_like(Wxh)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWho = np.zeros_like(Who)\n",
    "    eps = 1e-4\n",
    "    \n",
    "    for r in range(len(Wxh)):\n",
    "        for c in range(Wxh.shape[1]):\n",
    "            Wxh_pls = Wxh.copy()\n",
    "            Wxh_min = Wxh.copy()\n",
    "            \n",
    "            Wxh_pls[r, c] += eps\n",
    "            Wxh_min[r, c] -= eps\n",
    "            \n",
    "            l_pls = mse(x, y, Wxh_pls, Whh, Who)\n",
    "            l_min = mse(x, y, Wxh_min, Whh, Who)\n",
    "            \n",
    "            dWxh[r, c] = (l_pls - l_min) / (2*eps)\n",
    "    \n",
    "    for r in range(len(Whh)):\n",
    "        for c in range(Whh.shape[1]):\n",
    "            Whh_pls = Whh.copy()\n",
    "            Whh_min = Whh.copy()\n",
    "            \n",
    "            Whh_pls[r, c] += eps\n",
    "            Whh_min[r, c] -= eps\n",
    "            \n",
    "            l_pls = mse(x, y, Wxh, Whh_pls, Who)\n",
    "            l_min = mse(x, y, Wxh, Whh_min, Who)\n",
    "            \n",
    "            dWhh[r, c] = (l_pls - l_min) / (2*eps)\n",
    "    \n",
    "    for r in range(len(Who)):\n",
    "        for c in range(Who.shape[1]):\n",
    "            Who_pls = Who.copy()\n",
    "            Who_min = Who.copy()\n",
    "            \n",
    "            Who_pls[r, c] += eps\n",
    "            Who_min[r, c] -= eps\n",
    "            \n",
    "            l_pls = mse(x, y, Wxh, Whh, Who_pls)\n",
    "            l_min = mse(x, y, Wxh, Whh, Who_min)\n",
    "            \n",
    "            dWho[r, c] = (l_pls - l_min) / (2*eps)\n",
    "    \n",
    "    \n",
    "    return dWxh, dWhh, dWho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gradients():\n",
    "    for i in range(100):\n",
    "        W_xh = 0.1 * np.random.randn(3, 2)  # Wxh.shape: [n_in, n_hid]\n",
    "        W_hh = 0.1 * np.random.randn(2, 2)  # Whh.shape: [n_hid, n_hid]\n",
    "        W_ho = 0.1 * np.random.randn(2, 1)  # Who.shape: [n_hid, n_out]\n",
    "\n",
    "        xx = np.random.randn(100, 4, 3)\n",
    "        yy = np.random.randint(0, 2, size=[100, 1])\n",
    "\n",
    "        _, dW_xh, dW_hh, dW_ho = backward(xx, yy, W_xh, W_hh, W_ho)\n",
    "        ngW_xh, ngW_hh, ngW_ho = numerical_gradient(xx, yy, W_xh, W_hh, W_ho)\n",
    "\n",
    "        assert np.allclose(dW_xh, ngW_xh)\n",
    "        assert np.allclose(dW_hh, ngW_hh)\n",
    "        assert np.allclose(dW_ho, ngW_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gradients()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
